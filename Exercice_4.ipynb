{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4sblmkPtklEmQ14E6qCHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaetanAm/Master-1-Machine-Learning/blob/main/Exercice_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXERCICE 4"
      ],
      "metadata": {
        "id": "D2lHtc67an3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étape 1 : Charger le dataset"
      ],
      "metadata": {
        "id": "D8-ZzgPlaq5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Télécharger le fichier localement\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "HNc5v1JwNjJN",
        "outputId": "f6900986-e66b-4522-b3af-08747e51e1df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-67996e67-f780-40bd-b815-f098154c0f70\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-67996e67-f780-40bd-b815-f098154c0f70\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving creditcard.csv to creditcard.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le dataset à partir du fichier téléchargé\n",
        "data = pd.read_csv(list(uploaded.keys())[0])\n",
        "\n",
        "# Vérifier les premières lignes\n",
        "print(\"Aperçu du dataset :\")\n",
        "print(data.head())\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "print(\"\\nValeurs manquantes dans chaque colonne :\")\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8c37pXhOyXu",
        "outputId": "4d50da3b-697a-4fe3-b1fc-88e1d6f0ea78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aperçu du dataset :\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Valeurs manquantes dans chaque colonne :\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier les dimensions et la répartition des classes\n",
        "print(\"\\nDimensions des données :\", data.shape)\n",
        "print(\"Répartition des classes :\")\n",
        "print(data['Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJX82RalZirY",
        "outputId": "a78eb9a5-0f83-477b-aa11-a98bb9b9747c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensions des données : (284807, 31)\n",
            "Répartition des classes :\n",
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étape 2 : Préparer les données\n",
        "\n",
        "Définir les variables indépendantes (X) et dépendantes (y) :\n",
        "\n",
        "1.   Les colonnes V1 à V28 et Amount seront utilisées comme caractéristiques (X).\n",
        "2.   La colonne Class sera la cible (y).\n",
        "\n",
        "\n",
        "\n",
        "Créer les variables X et y :"
      ],
      "metadata": {
        "id": "o6GZlfGoayul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparer les caractéristiques et la cible\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "print(\"Dimensions de X :\", X.shape)\n",
        "print(\"Dimensions de y :\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHJ7OyTQZnfa",
        "outputId": "4b3904e2-2682-43ec-f662-03ff5e6028f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions de X : (284807, 30)\n",
            "Dimensions de y : (284807,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étape 3 : Diviser en ensembles d'entraînement et de test\n",
        "On Utilise train_test_split de sklearn pour diviser les données en deux ensembles :\n",
        "\n",
        "\n",
        "1.   Entraînement (train) : pour ajuster le modèle.\n",
        "2.   Test : pour évaluer les performances du modèle.\n",
        "\n"
      ],
      "metadata": {
        "id": "_hfH0yFRbb-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Diviser les données en train et test avec stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Vérifier les dimensions\n",
        "print(\"Dimensions de X_train :\", X_train.shape)\n",
        "print(\"Dimensions de X_test :\", X_test.shape)\n",
        "print(\"Répartition des classes dans y_train :\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"Répartition des classes dans y_test :\")\n",
        "print(y_test.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z4T1a0DZp5w",
        "outputId": "e67183aa-02d7-4a76-951e-b3d05e48b30c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions de X_train : (227845, 30)\n",
            "Dimensions de X_test : (56962, 30)\n",
            "Répartition des classes dans y_train :\n",
            "Class\n",
            "0    0.998271\n",
            "1    0.001729\n",
            "Name: proportion, dtype: float64\n",
            "Répartition des classes dans y_test :\n",
            "Class\n",
            "0    0.99828\n",
            "1    0.00172\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étape 4 : Standardiser les données\n",
        "\n",
        "Pour améliorer la convergence des modèles (comme la régression logistique), on standardise les données en mettant toutes les colonnes sur une échelle comparable."
      ],
      "metadata": {
        "id": "i4STo2pObmMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialiser le scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Appliquer la standardisation sur les ensembles d'entraînement et de test\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Standardisation terminée.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wc8OoOVZs40",
        "outputId": "8283e227-e139-44f2-ff00-8bd9c0a6b5e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardisation terminée.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étape 5 : Appliquer SMOTE\n",
        "\n",
        "Nous utilisons la bibliothèque imblearn pour appliquer SMOTE sur les données d'entraînement."
      ],
      "metadata": {
        "id": "06IdCBdcb8D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Appliquer SMOTE à l'ensemble d'entraînement\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Vérifier la répartition des classes après SMOTE\n",
        "print(\"Répartition des classes après SMOTE :\")\n",
        "print(Counter(y_train_smote))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6z53lAwZ5lG",
        "outputId": "8c104aa1-ae8a-4715-be56-5f69625a9cd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Répartition des classes après SMOTE :\n",
            "Counter({0: 227451, 1: 227451})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étape 6 : Entraîner et évaluer le modèle\n",
        "\n",
        "Nous allons entraîner un modèle de régression logistique sur les données équilibrées avec SMOTE et le comparer à un modèle entraîné sur les données originales."
      ],
      "metadata": {
        "id": "sJYYwClTb_uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Modèle sur les données originales\n",
        "model_original = LogisticRegression(max_iter=200, random_state=42)\n",
        "model_original.fit(X_train_scaled, y_train)\n",
        "y_pred_original = model_original.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nRapport de classification (données originales) :\")\n",
        "print(classification_report(y_test, y_pred_original))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZlobvN9Z-Ql",
        "outputId": "9f9fedba-88b8-42e8-b742-9d1b0dc89f48"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rapport de classification (données originales) :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.83      0.63      0.72        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.91      0.82      0.86     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modèle sur les données SMOTE\n",
        "model_smote = LogisticRegression(max_iter=200, random_state=42)\n",
        "model_smote.fit(X_train_smote, y_train_smote)\n",
        "y_pred_smote = model_smote.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nRapport de classification (données SMOTE) :\")\n",
        "print(classification_report(y_test, y_pred_smote))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TBX9KgBaBqJ",
        "outputId": "ca2f28a1-7045-4ada-da0b-3ef12a2a8e7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rapport de classification (données SMOTE) :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56864\n",
            "           1       0.06      0.92      0.11        98\n",
            "\n",
            "    accuracy                           0.97     56962\n",
            "   macro avg       0.53      0.95      0.55     56962\n",
            "weighted avg       1.00      0.97      0.99     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Étape 8 : Analyse et conclusion pour l'exercice 4\n",
        "\n",
        "D'après les résultats obtenus, voici une analyse détaillée pour conclure l'exercice :\n",
        "\n",
        "---\n",
        "\n",
        "#### Comparaison des résultats\n",
        "\n",
        "| **Modèle**           | **Classe** | **Précision** | **Rappel** | **F1-score** | **Support** |\n",
        "|-----------------------|------------|---------------|------------|--------------|-------------|\n",
        "| Données originales    | 0 (légitime) | **1.00**      | **1.00**   | **1.00**     | 56864       |\n",
        "|                       | 1 (fraude)   | 0.83          | 0.63       | 0.72         | 98          |\n",
        "| **Moyenne macro**     | -           | 0.91          | 0.82       | 0.86         | 56962       |\n",
        "| **Accuracy globale**  | -           | **1.00**      | -          | -            | 56962       |\n",
        "| Données SMOTE         | 0 (légitime) | **1.00**      | 0.97       | 0.98         | 56864       |\n",
        "|                       | 1 (fraude)   | 0.06          | **0.92**   | 0.11         | 98          |\n",
        "| **Moyenne macro**     | -           | 0.53          | **0.95**   | 0.55         | 56962       |\n",
        "| **Accuracy globale**  | -           | 0.97          | -          | -            | 56962       |\n",
        "\n",
        "---\n",
        "\n",
        "#### Analyse des résultats\n",
        "\n",
        "1. **Modèle avec les données originales :**\n",
        "   - Le modèle a une précision parfaite pour les transactions légitimes (**1.00**) mais une performance modérée pour les fraudes.\n",
        "   - Le rappel de 0.63 pour les fraudes montre que 37 % des fraudes ne sont pas détectées.\n",
        "   - Ce modèle est biaisé en faveur de la classe majoritaire (transactions légitimes).\n",
        "\n",
        "2. **Modèle avec les données SMOTE :**\n",
        "   - Le rappel pour les fraudes est nettement amélioré (**0.92**), détectant presque toutes les fraudes.\n",
        "   - La précision pour les fraudes est très faible (**0.06**), ce qui signifie un grand nombre de faux positifs.\n",
        "   - Bien que le rappel pour les transactions légitimes reste élevé (**0.97**), la précision générale est impactée.\n",
        "\n",
        "---\n",
        "\n",
        "#### Étape 9 : Conclusion finale\n",
        "\n",
        "- **Amélioration avec SMOTE** :\n",
        "  - L'utilisation de SMOTE améliore considérablement la capacité du modèle à détecter les fraudes (rappel élevé pour la classe 1).\n",
        "  - Cependant, la faible précision montre que beaucoup de transactions légitimes sont mal classées comme frauduleuses.\n",
        "\n",
        "- **Application pratique :**\n",
        "  - Dans un système de détection de fraude, un rappel élevé est souvent prioritaire pour capturer un maximum de fraudes, même au prix de quelques faux positifs.\n",
        "  - Pour améliorer la précision tout en conservant un bon rappel, il serait pertinent d'utiliser un modèle d'ensemble (comme un Random Forest) ou d'ajuster les seuils de décision.\n",
        "\n"
      ],
      "metadata": {
        "id": "13qiQSZIcG-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "---\n",
        "\n",
        "Dans cet exercice, nous avons appliqué la méthode **SMOTE (Synthetic Minority Oversampling Technique)** pour équilibrer les classes dans le dataset de détection de fraudes, en créant des échantillons synthétiques pour la classe minoritaire. Voici un résumé de nos observations et analyses :\n",
        "\n",
        "---\n",
        "\n",
        "#### Résumé des résultats\n",
        "1. **Modèle avec les données originales :**\n",
        "   - Ce modèle présente une excellente précision globale (**accuracy : 1.00**), mais il est fortement biaisé en faveur de la classe dominante (transactions légitimes).\n",
        "   - Le rappel pour les fraudes est modéré (**0.63**), ce qui signifie que 37 % des fraudes passent inaperçues.\n",
        "   - Cette approche est inadéquate dans un contexte où la détection des fraudes est critique, car elle manque de fiabilité pour capturer toutes les fraudes.\n",
        "\n",
        "2. **Modèle avec les données SMOTE :**\n",
        "   - Le rappel pour la classe fraude augmente considérablement à **0.92**, détectant presque toutes les transactions frauduleuses.\n",
        "   - Cependant, la précision pour la classe fraude diminue à **0.06**, ce qui génère un grand nombre de faux positifs (transactions légitimes mal classées comme fraudes).\n",
        "   - L'**accuracy globale** diminue légèrement à **0.97**, mais ce compromis est acceptable si l'objectif principal est de maximiser la détection des fraudes.\n",
        "\n",
        "---\n",
        "\n",
        "#### Interprétation des résultats\n",
        "- **Avantages de SMOTE** :\n",
        "  - SMOTE a permis d'équilibrer les données et d'améliorer la capacité du modèle à détecter les fraudes.\n",
        "  - C'est une méthode efficace pour traiter le déséquilibre des classes dans des datasets où la classe minoritaire est cruciale.\n",
        "\n",
        "- **Inconvénients de SMOTE** :\n",
        "  - L'amélioration du rappel pour la classe fraude s'accompagne d'une baisse significative de la précision, ce qui peut poser problème dans des scénarios où les faux positifs doivent être minimisés.\n",
        "\n",
        "---\n",
        "\n",
        "#### Recommandations\n",
        "1. **Utilisation dans un système réel :**\n",
        "   - Si le rappel est prioritaire (par exemple, pour examiner manuellement les transactions détectées comme frauduleuses), SMOTE est une solution viable.\n",
        "   - Cependant, pour améliorer la précision, il serait utile d'explorer d'autres approches, comme :\n",
        "     - Ajuster les seuils de décision du modèle.\n",
        "     - Utiliser des modèles d'ensemble (Random Forest, XGBoost).\n",
        "     - Combiner SMOTE avec des techniques de sélection de caractéristiques pour éviter d'introduire du bruit.\n",
        "\n",
        "2. **Pistes d'amélioration** :\n",
        "   - Tester des algorithmes plus robustes pour le déséquilibre des classes (par exemple, **Balanced Random Forest** ou **AdaBoost**).\n",
        "   - Comparer SMOTE avec d'autres techniques d'équilibrage, comme **ADASYN** ou **Borderline-SMOTE**.\n",
        "\n",
        "---\n",
        "\n",
        "En conclusion, SMOTE est une méthode puissante pour traiter le déséquilibre des classes et maximiser le rappel pour la détection des fraudes. Cependant, pour minimiser les faux positifs, des ajustements supplémentaires ou des modèles alternatifs doivent être envisagés."
      ],
      "metadata": {
        "id": "1esRdBnYcPu7"
      }
    }
  ]
}