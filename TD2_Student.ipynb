{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaetanAm/Master-1-Machine-Learning/blob/main/TD2_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98529be5-c1d5-4f25-8547-1e39f30a1dac",
      "metadata": {
        "id": "98529be5-c1d5-4f25-8547-1e39f30a1dac"
      },
      "source": [
        "# TP2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b5874f-06e0-4a3c-b2a5-1b2902bccacc",
      "metadata": {
        "id": "61b5874f-06e0-4a3c-b2a5-1b2902bccacc"
      },
      "source": [
        "This tutorial consists of two independent parts to illustrate the applications of Machine Learning in asset management:\n",
        "* Linear regression model to predict the future performance of Amazon stock. (cf. CM3)\n",
        "* Markowitz optimization problem with L2 regularization. (cf. CM4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "256baf8f-b755-43b7-a54e-6becbf924c80",
      "metadata": {
        "id": "256baf8f-b755-43b7-a54e-6becbf924c80"
      },
      "source": [
        "## Part I: Linear regression model to predict the future performance of Amazon stock\n",
        "This part involves building the linear regression model to predict the future performance of Amazon (NYSE) stock. Mathematically, we will build a linear model:\n",
        "$$Y_{t, 10}=\\sum_{k=1}^S \\beta_t F_t^{(k)}+\\epsilon_t, \\quad \\epsilon_t \\sim N\\left(0, \\sigma_t^2\\right)$$\n",
        "$Y_{t, 10}$ denotes the return of the next 10 days to be predicted, and $F_{t}^{(k)}$ denotes $k$-th feature used in the linear predictive model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd306e82-4bb1-42c3-8b8a-63d0a8622bb1",
      "metadata": {
        "id": "fd306e82-4bb1-42c3-8b8a-63d0a8622bb1"
      },
      "source": [
        "### Preparation\n",
        "First, we'll import the historical prices (close) of the Amazon stock and calculate the returns and moving averages as features of the linear model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99acc796-9ae0-44b0-b573-b41c7ef22a7e",
      "metadata": {
        "id": "99acc796-9ae0-44b0-b573-b41c7ef22a7e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#### Import data ####\n",
        "stock_price = pd.read_excel(\"TD2_Amazon.xlsx\", sheet_name = 0, index_col = [0], header = [0])\n",
        "stock_price.index.name = None\n",
        "stock_price.index = pd.to_datetime(stock_price.index, format = \"%Y-%m-%d\")\n",
        "\n",
        "#### Plot historical prices ####\n",
        "stock_price_normalised = stock_price/stock_price.iloc[0]\n",
        "stock_price_normalised.plot(figsize = (10, 5), grid = False, linewidth = 1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7404da76-e4f1-4540-b678-b6dfb5a42ff2",
      "metadata": {
        "id": "7404da76-e4f1-4540-b678-b6dfb5a42ff2"
      },
      "source": [
        "We will construct the explained and explanatory variables of our linear model:\n",
        "* The explained variable denotes the next 10-day return to be predicted.\n",
        "* The explanatory variables are moving averages with different windows (1, 2, 4, 8, 16, 32, 64, 128) on daily returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b7e3982-6a7b-4006-ab68-d8556e2c1a24",
      "metadata": {
        "id": "6b7e3982-6a7b-4006-ab68-d8556e2c1a24"
      },
      "outputs": [],
      "source": [
        "#### Daily return ####\n",
        "daily_return = stock_price.pct_change()\n",
        "\n",
        "# Calculate the 10-day forward return\n",
        "forward_price = stock_price.shift(-10)  # Shift prices by -10 days\n",
        "forward_return= (forward_price - stock_price) / stock_price  # Calculate returns\n",
        "\n",
        "\n",
        "# We compute the moving averages of the returns with different “Windows” to prepare “features” in the regression model.\n",
        "Ftm_1    = daily_return\n",
        "Ftm_2    = daily_return.rolling(2).mean()\n",
        "Ftm_4    = daily_return.rolling(4).mean()\n",
        "Ftm_8    = daily_return.rolling(8).mean()\n",
        "Ftm_16   = daily_return.rolling(16).mean()\n",
        "Ftm_32   = daily_return.rolling(32).mean()\n",
        "Ftm_64   = daily_return.rolling(64).mean()\n",
        "Ftm_128  = daily_return.rolling(128).mean()\n",
        "\n",
        "all_data = pd.concat([Ftm_1, Ftm_2, Ftm_4, Ftm_8, Ftm_16, Ftm_32, Ftm_64, Ftm_128, forward_return], axis = 1).dropna().head(300)\n",
        "all_data.columns = ['Ftm1', 'Ftm2', 'Ftm4', 'Ftm8', 'Ftm16', 'Ftm32', 'Ftm64', 'Ftm128', 'forward_return']\n",
        "features = all_data[['Ftm1', 'Ftm2', 'Ftm4', 'Ftm8', 'Ftm16', 'Ftm32', 'Ftm64', 'Ftm128']]\n",
        "label = all_data['forward_return']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db751dd3-40c8-4edf-a35d-287acad1767d",
      "metadata": {
        "id": "db751dd3-40c8-4edf-a35d-287acad1767d"
      },
      "source": [
        "**Q1: Correlation analysis**\n",
        "\n",
        "We're going to calculate the correlation coefficients between the explained variables and our feature vectors. What can you say about these correlations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4deae96b-affe-4b56-b921-fb5f81bbb696",
      "metadata": {
        "id": "4deae96b-affe-4b56-b921-fb5f81bbb696"
      },
      "outputs": [],
      "source": [
        "correlations = #...#\n",
        "\n",
        "# Plotting the correlations using a bar plot\n",
        "plt.bar(features.columns.to_list(), correlations)\n",
        "plt.xlabel('Columns of Features')\n",
        "plt.ylabel('Correlation with Label')\n",
        "plt.title('Correlation of Label with Each Column of Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc644b5-c7c5-4690-bd4e-b74bd8ac17bb",
      "metadata": {
        "id": "ddc644b5-c7c5-4690-bd4e-b74bd8ac17bb"
      },
      "source": [
        "We can see that the dominant correlations are provided by $F_{tmK}$ with $ K\\geq 8$. We can reasonably expect our model selection to choose most of the variables in this subset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fba678-2d89-4e88-80aa-5433fa557f9a",
      "metadata": {
        "id": "94fba678-2d89-4e88-80aa-5433fa557f9a"
      },
      "source": [
        "**Q2: Preprocessing**\n",
        "\n",
        "Our regression model assumes a homoscedastic process. It is therefore necessary to standardize the explained variable and the feature vectors in the regression process.\n",
        "\n",
        "* For the explained variable $Y_{t, 10}$, a mean of zero is sufficient.\n",
        "* For the feature vectors $F_{tmK}$, each factor needs to be standardized to have a mean of zero and a unit variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcd430cb-423c-49de-899d-826d852c758d",
      "metadata": {
        "id": "fcd430cb-423c-49de-899d-826d852c758d"
      },
      "outputs": [],
      "source": [
        "Yt = label.values\n",
        "Ycen = #...#\n",
        "\n",
        "# Standardizing the matrix Features\n",
        "scaler = StandardScaler()\n",
        "Mnorm = #...#\n",
        "Mnorm_df = pd.DataFrame(Mnorm, columns = features.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181fa97a-71d7-429a-a137-e4de3b574401",
      "metadata": {
        "id": "181fa97a-71d7-429a-a137-e4de3b574401"
      },
      "source": [
        "**Q3: Linear regression**\n",
        "\n",
        "We can now build a linear model using all the features and **sm.OLS()** function. What can you conclude from the model summary?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c0409b-140d-4aed-a185-f26a3aa2d343",
      "metadata": {
        "id": "a1c0409b-140d-4aed-a185-f26a3aa2d343"
      },
      "outputs": [],
      "source": [
        "#### Ordinary least squares (OLS) regression ####\n",
        "X = sm.add_constant(Mnorm_df)  # Add constant for intercept\n",
        "linModelFull = #...#\n",
        "\n",
        "# Summary of the full model\n",
        "print(linModelFull.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4e6b774-f88c-49d0-beba-83dfc6cffb38",
      "metadata": {
        "id": "b4e6b774-f88c-49d0-beba-83dfc6cffb38"
      },
      "source": [
        "**Q4: Backward method for variable selection**\n",
        "\n",
        "We'll apply the Backward method for variable selection. At each stage, we remove the variable with the highest t-statistics p-value. Let's call this reduced model **linModelRed**. What can you conclude by comparing the selected features with the correlation analysis? How do we know that the reduced model preserves the same goodness of fit as the full model? (Hint: We can use **sm.stats.anova_lm** function to compare the two models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba20cd3-b4f9-43f9-b758-81f811a1d4a3",
      "metadata": {
        "id": "0ba20cd3-b4f9-43f9-b758-81f811a1d4a3"
      },
      "outputs": [],
      "source": [
        "#### Backward method for variable selection ####\n",
        "print('Step 1')\n",
        "linModelRed = #...#\n",
        "print(linModelRed.summary())\n",
        "print('\\n\\n')\n",
        "\n",
        "print('Step 2')\n",
        "linModelRed = #...#\n",
        "print(linModelRed.summary())\n",
        "print('\\n\\n')\n",
        "\n",
        "#...#\n",
        "\n",
        "# F-test: model comparison\n",
        "print('Model comparison')\n",
        "anova_results = #...#\n",
        "print(anova_results)\n",
        "print('\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "242c8950-9fb2-488e-8254-443ab04de0c6",
      "metadata": {
        "id": "242c8950-9fb2-488e-8254-443ab04de0c6"
      },
      "source": [
        "**Q5: Ridge and Lasso**\n",
        "\n",
        "We can use the **sm.OLS().fit_regularized** function to perform ridge and lasso regressions. Read the document https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit_regularized.html and complete the following codes. Compare the two figures and interpret them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8094dfe-6a97-42e9-b1ed-5a3abb118a79",
      "metadata": {
        "id": "c8094dfe-6a97-42e9-b1ed-5a3abb118a79"
      },
      "outputs": [],
      "source": [
        "recap_lasso = list()\n",
        "recap_ridge = list()\n",
        "for ind_alpha in np.logspace(-6, 1, 100):\n",
        "    X = sm.add_constant(Mnorm)\n",
        "    lasso_result = #...#\n",
        "    ridge_result = #...#\n",
        "    recap_lasso.append(lasso_result.params)\n",
        "    recap_ridge.append(ridge_result.params)\n",
        "\n",
        "res_lasso = pd.DataFrame(recap_lasso, columns = ['Intercept', 'Ftm1', 'Ftm2', 'Ftm4', 'Ftm8', 'Ftm16', 'Ftm32', 'Ftm64', 'Ftm128'])\n",
        "plt.figure()\n",
        "res_lasso.plot(figsize = (10, 5), grid = False, linewidth = 1.5)\n",
        "plt.title(\"LASSO\")\n",
        "plt.xlabel(\"Regularization\")\n",
        "plt.ylabel(\"Parameters\")\n",
        "\n",
        "res_ridge = pd.DataFrame(recap_ridge, columns = ['Intercept', 'Ftm1', 'Ftm2', 'Ftm4', 'Ftm8', 'Ftm16', 'Ftm32', 'Ftm64', 'Ftm128'])\n",
        "plt.figure()\n",
        "res_ridge.plot(figsize = (10, 5), grid = False, linewidth = 1.5)\n",
        "plt.title(\"RIDGE\")\n",
        "plt.xlabel(\"Regularization\")\n",
        "plt.ylabel(\"Parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c436e48d-ba2d-496c-b078-243fe1ed99f0",
      "metadata": {
        "id": "c436e48d-ba2d-496c-b078-243fe1ed99f0"
      },
      "source": [
        "## Part II: Markowitz optimization problem with L2 regularization\n",
        "\n",
        "In this exercise, we'll use data from 4 US stocks (Coca Cola, Citi Group, Walmart, Nike) to illustrate the L2 regularization technique in portfolio optimization (Markowitz mean-variance optimization).\n",
        "\n",
        "We have a database with 2770 rows (number of observations) and 4 columns (number of companies)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e716c1-064d-46c8-8390-bee9741e52b3",
      "metadata": {
        "id": "b1e716c1-064d-46c8-8390-bee9741e52b3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#### Import data ####\n",
        "stock_price = pd.read_csv(\"TD2_MVO.csv\", index_col = [0], header = [0], sep = \";\")\n",
        "stock_price.index.name = None\n",
        "stock_price.index = pd.to_datetime(stock_price.index, format = \"%d/%m/%Y\")\n",
        "\n",
        "print(stock_price.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da6f8a6c-9fc1-467b-9962-5bb12261671e",
      "metadata": {
        "id": "da6f8a6c-9fc1-467b-9962-5bb12261671e"
      },
      "outputs": [],
      "source": [
        "#### Plot historical prices ####\n",
        "stock_price_normalised = stock_price/stock_price.iloc[0]\n",
        "stock_price_normalised.plot(figsize = (10, 5), grid = False, linewidth = 1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e0fe55-20b0-4746-9e49-b2a257dcb973",
      "metadata": {
        "id": "c1e0fe55-20b0-4746-9e49-b2a257dcb973"
      },
      "source": [
        "### II.1/ Tracing the efficient frontier using the simulation method\n",
        "\n",
        "The aim of this section is to generate 5,000 fictitious portfolios (random combinations of 4 stocks) to visualize the efficient frontier in Markowitz theory.\n",
        "\n",
        "We first calculate the compound annual growth rate (CGAR) and annual volatility for each asset with the functions in TD1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c3951c7-2d98-4faf-b8c2-17b61cffcd00",
      "metadata": {
        "id": "4c3951c7-2d98-4faf-b8c2-17b61cffcd00"
      },
      "outputs": [],
      "source": [
        "# Function to compute Compound Annual Growth Rate (CAGR)\n",
        "def compute_cagr(price, ann_multiple=252):\n",
        "    n = len(price)\n",
        "    cagr = (price.iloc[-1] / price.iloc[0]) ** (ann_multiple / n) - 1\n",
        "    return cagr\n",
        "\n",
        "# Function to compute Volatility\n",
        "def compute_vol(price, ann_multiple=252):\n",
        "    ret = price / price.shift(1) - 1  # Calculate returns\n",
        "    n = len(price)  # Get the length of the time series\n",
        "    mu = np.nanmean(ret)  # Calculate the mean\n",
        "    sigma_daily = np.sqrt(np.nansum((ret - mu) ** 2) / (n - 1))  # Calculate daily volatility\n",
        "    sigma = np.sqrt(ann_multiple) * sigma_daily  # Annualize the volatility\n",
        "    return sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b137398-bc98-4077-9c85-4a651589feb6",
      "metadata": {
        "id": "7b137398-bc98-4077-9c85-4a651589feb6"
      },
      "source": [
        "**Q1: Use the '.apply' and 'compute_cagr' functions to calculate the CAGR for each stock**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a769b8-71aa-4895-b0fc-76e1022807ef",
      "metadata": {
        "id": "63a769b8-71aa-4895-b0fc-76e1022807ef"
      },
      "outputs": [],
      "source": [
        "mus = #...#\n",
        "mus = mus.values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c77a31-382a-4da1-a000-168a5c06bd9b",
      "metadata": {
        "id": "73c77a31-382a-4da1-a000-168a5c06bd9b"
      },
      "source": [
        "**Q2: Calculate the returns for each stock, then calculate the (annual) covariance matrix using the 'cov' function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a814414-b8f1-4dfe-850d-c62fcbc5806a",
      "metadata": {
        "id": "7a814414-b8f1-4dfe-850d-c62fcbc5806a"
      },
      "outputs": [],
      "source": [
        "stock_return = #...#\n",
        "Sigma = #...#\n",
        "Sigma = Sigma.values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74154bb8-7835-4b45-a45a-6ed9629786fc",
      "metadata": {
        "id": "74154bb8-7835-4b45-a45a-6ed9629786fc"
      },
      "source": [
        "In the next section, we'll simulate the stock allocations to build the fictitious portfolios. To do this, we can simulate 4 numbers from 0 to 1 and then normalize them to sum to 100%. We simulate a total of 5,000 fictitious portfolios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc99ade-1123-44e3-ba9b-755c44f891db",
      "metadata": {
        "id": "5dc99ade-1123-44e3-ba9b-755c44f891db"
      },
      "source": [
        "**Q3: Calculate the portfolio return and volatility of the fictitious portfolio using the @ operator (matrix product)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e4b7429-23db-4f03-b9e8-f3fdbb50cdb0",
      "metadata": {
        "id": "5e4b7429-23db-4f03-b9e8-f3fdbb50cdb0"
      },
      "outputs": [],
      "source": [
        "num_asset = stock_return.shape[1]\n",
        "num_portfolios = 5000\n",
        "\n",
        "recap_port_ret, recap_port_vol, recap_port_SR = list(), list(), list()\n",
        "for ind in range(0, num_portfolios):\n",
        "    weights = np.random.uniform(0, 1, num_asset)\n",
        "    weights = weights/weights.sum()\n",
        "\n",
        "    #### Q3: Calculate the portfolio return and volatility of the fictitious portfolio with the @ operator (matrix product) ####\n",
        "    port_ret = #...#\n",
        "    port_vol = #...#\n",
        "    port_SR = #...#\n",
        "\n",
        "    recap_port_ret.append(port_ret)\n",
        "    recap_port_vol.append(port_vol)\n",
        "    recap_port_SR.append(port_SR)\n",
        "\n",
        "res_port_ret = pd.Series(recap_port_ret)\n",
        "res_port_vol = pd.Series(recap_port_vol)\n",
        "res_port_SR = pd.Series(recap_port_SR)\n",
        "\n",
        "#### Tracer la frontiere efficiente ####\n",
        "plt.figure(figsize = (10, 5))\n",
        "plt.scatter(res_port_vol, res_port_ret, s = 10)\n",
        "plt.xlim(0.1, 0.5)\n",
        "plt.ylim(0, 0.25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f35d8e-e85a-4e7e-8119-9f2d220d0fc5",
      "metadata": {
        "id": "51f35d8e-e85a-4e7e-8119-9f2d220d0fc5"
      },
      "source": [
        "Each point represents a fictitious portfolio. The scatter plot therefore represents all possible combinations of the four stocks. The existence of the efficient frontier is clearly visible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f9abb0-d45b-45a1-8ff8-3a04aabad101",
      "metadata": {
        "id": "08f9abb0-d45b-45a1-8ff8-3a04aabad101"
      },
      "source": [
        "### II.2/ Plot the efficient frontier using quadratic programming\n",
        "\n",
        "The aim of this section is to repeat the previous exercise and find the efficient frontier using quadratic programming.\n",
        "\n",
        "We will use the $\\gamma$-problem form of the Markowitz optimization problem (CM4) and recall that $\\gamma$ is the trade-off coefficient between expected return and volatility.\n",
        "\n",
        "**$\\gamma$-problem**\n",
        "\n",
        "$$w^{\\star}(\\gamma)=\\arg \\min \\frac{1}{2} w^{T} \\Sigma w-\\gamma w^{T} \\mu$$\n",
        "$$\\text{s.c.} \\quad w^{T} \\mathbf{1}= \\sum_{i}w_{i} = 1 $$\n",
        "$$ \\quad  \\quad  \\quad w_{i} \\geq 0, \\forall i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f1fa5b5-7c91-4c29-a1e2-31c195c70fe9",
      "metadata": {
        "id": "6f1fa5b5-7c91-4c29-a1e2-31c195c70fe9"
      },
      "source": [
        "$\\gamma$-problem can be written in the form of quadratic programming (CM4).\n",
        "\n",
        "**Quadratic programming:**\n",
        "$$\\begin{array}{c}\n",
        "w^{\\star}=\\arg \\min \\frac{1}{2} w^{T} Q w-w^{T} R \\\\\n",
        "\\text { s.c. } S w \\leq T\n",
        "\\end{array}$$\n",
        "with\n",
        "$$Q=\\Sigma \\quad R=\\gamma \\mu$$\n",
        "$$\\begin{array}{lll}\n",
        "\\begin{array}{c} w^{T} \\mathbf{1}=1 \\\\\n",
        " w_{i} \\geq 0, \\forall i \\end{array} & \\Leftrightarrow & \\underbrace{\\left[\\begin{array}{c}\n",
        "-(1, 1, ..., 1) \\\\\n",
        "(1, 1, ..., 1) \\\\\n",
        "-I_{n}\n",
        "\\end{array}\\right]}_S w \\leq \\underbrace{\\left[\\begin{array}{c}\n",
        "-1 \\\\\n",
        "1 \\\\\n",
        "\\mathbf{0}_{n}\n",
        "\\end{array}\\right]}_{T} & \\Leftrightarrow \\quad S w \\leq T \\\\\n",
        "\\end{array}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65959e4e-c434-4448-8571-3ace6a591a92",
      "metadata": {
        "id": "65959e4e-c434-4448-8571-3ace6a591a92"
      },
      "source": [
        "We can use the 'solve_qp' function in the 'qpsolvers' package to perform quadratic programming in python. We need to read the 'solve_qp' function document carefully https://qpsolvers.github.io/qpsolvers/quadratic-programming.html and decide on the argument values: **P**, **q**, **A**, **b**, **G** and **h**.\n",
        "\n",
        "$$\\begin{array}{c}\n",
        "\\min \\frac{1}{2} w^{T} P w + w^{T} q  \\\\\n",
        "\\text { s.c. } G w \\leq h \\\\\n",
        "\\quad  \\quad  A w = b\\end{array}$$\n",
        "\n",
        "We'll solve the optimization problem in the form of quadratic programming for the different values of $\\gamma$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df00d660-9bb8-4988-aaad-e864a0611e9a",
      "metadata": {
        "id": "df00d660-9bb8-4988-aaad-e864a0611e9a"
      },
      "source": [
        "**Q4: Determine the arguments for quadratic programming and calculate the portfolio return and portfolio volatility with the @ operator.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe3fb62-2b1d-4a97-9501-5cf6b41a6dae",
      "metadata": {
        "id": "7fe3fb62-2b1d-4a97-9501-5cf6b41a6dae"
      },
      "outputs": [],
      "source": [
        "from qpsolvers import solve_qp\n",
        "\n",
        "gammas = np.arange(0, 3.01, 0.01)\n",
        "recap_port_ret_QP, recap_port_vol_QP, recap_port_SR_QP = list(), list(), list()\n",
        "\n",
        "for ind_gamma in gammas:\n",
        "    #### Q4: Determine arguments for quadratic programming  ####\n",
        "    P = #...#\n",
        "    q = #...#\n",
        "\n",
        "    A = #...#\n",
        "    b = #...#\n",
        "\n",
        "    G = #...#\n",
        "    h = #...#\n",
        "\n",
        "    weights_QP = solve_qp(P, q, G, h, A, b, solver = \"ecos\")\n",
        "\n",
        "    port_ret_QP = #...#\n",
        "    port_vol_QP = #...#\n",
        "    port_SR_QP = #...#\n",
        "\n",
        "    recap_port_ret_QP.append(port_ret_QP)\n",
        "    recap_port_vol_QP.append(port_vol_QP)\n",
        "    recap_port_SR_QP.append(port_SR_QP)\n",
        "\n",
        "\n",
        "recap_port_ret_QP = pd.Series(recap_port_ret_QP)\n",
        "res_port_vol_QP = pd.Series(recap_port_vol_QP)\n",
        "res_port_SR_QP = pd.Series(recap_port_SR_QP)\n",
        "\n",
        "#### Plot efficient frontier ####\n",
        "plt.figure(figsize = (10, 5))\n",
        "plt.scatter(res_port_vol, res_port_ret, s = 10)\n",
        "plt.plot(res_port_vol_QP, recap_port_ret_QP, color = 'red', linewidth = 5)\n",
        "plt.xlim(0.1, 0.5)\n",
        "plt.ylim(0, 0.25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62467cb5-3cb7-4160-9afe-210a9e52a6fa",
      "metadata": {
        "id": "62467cb5-3cb7-4160-9afe-210a9e52a6fa"
      },
      "source": [
        "We can see that the efficient frontier is well aligned with the point cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c3c58d3-7bf1-4d89-a358-418a54ce2fb0",
      "metadata": {
        "id": "4c3c58d3-7bf1-4d89-a358-418a54ce2fb0"
      },
      "source": [
        "### II.3/ Portfolio allocation over time\n",
        "\n",
        "In this section, we set the value of $\\gamma = 0.02$ and rebalance the portfolio every month. At each rebalancing date, we use one year of past data to estimate expected return and volatility.\n",
        "\n",
        "**Q5: We need to use the answers to Q1$\\sim$Q4 to fill in the blanks in the codes below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae301c57-e4f8-4d95-906e-a1a4d8f68c32",
      "metadata": {
        "id": "ae301c57-e4f8-4d95-906e-a1a4d8f68c32"
      },
      "outputs": [],
      "source": [
        "gamma = 0.02\n",
        "num_observation = stock_return.shape[0]\n",
        "index_rebalancement = stock_return['2010':].resample('M').last().index\n",
        "weights_backtest = pd.DataFrame(index = index_rebalancement, columns = stock_return.columns)\n",
        "\n",
        "for ind in index_rebalancement:\n",
        "    price_tmp = stock_price[:ind].tail(252)\n",
        "    return_tmp = price_tmp.pct_change().dropna()\n",
        "\n",
        "    mus_tmp = #...#\n",
        "    mus_tmp = mus_tmp.values\n",
        "\n",
        "    Sigma_tmp = #...#\n",
        "    Sigma_tmp = Sigma_tmp.values\n",
        "\n",
        "    P = #...#\n",
        "    q = #...#\n",
        "\n",
        "    A = #...#\n",
        "    b = #...#\n",
        "\n",
        "    G = #...#\n",
        "    h = #...#\n",
        "\n",
        "    weights_QP_tmp = solve_qp(P, q, G, h, A, b, solver = \"ecos\")\n",
        "    weights_backtest.loc[ind] = weights_QP_tmp\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "#### Plot portfolio allocation over time ####\n",
        "weights_backtest.abs().plot(kind='area', stacked=True, cmap='tab20', figsize=(15, 6))\n",
        "plt.title(\"Backtest\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Allocation\")\n",
        "plt.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.1), fancybox = True, shadow = True, ncol = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "305fd704-bd08-4af5-a4d6-be75c4f5350d",
      "metadata": {
        "id": "305fd704-bd08-4af5-a4d6-be75c4f5350d"
      },
      "source": [
        "### II.4/ The L2 regularization technique\n",
        "\n",
        "In this section, we'll look at the application of the L2 regularization technique. The aim is to solve the instability problem in Markowitz mean-variance optimization and reduce portfolio turnovers. We recall that the optimization problem ( $\\gamma$-problem) with L2 regularization can be written as:\n",
        "\n",
        "$$ \\begin{array}{c}\n",
        "w^{\\star}=\\arg \\min \\frac{1}{2} w^{T} \\Sigma w-\\gamma w^{T} \\mu+\\rho \\left\\|w-w_{old}\\right\\|_{2}^{2} \\\\\n",
        "\\text { s.c. } \\quad w^{T} \\mathbf{1}=1 \\\\\n",
        "\\quad  \\quad  \\quad  \\quad w_{i} \\geq 0, \\forall i\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "$w_{old}$ means the allocation of the previous rebalancing date.\n",
        "\n",
        "We can also write the objective function of the above problem in quadratic programming form:\n",
        "$$ \\begin{array}{c}\n",
        "w^{\\star}=\\arg \\min \\frac{1}{2} w^{T} \\Sigma w-\\gamma w^{T} \\mu+\\rho \\left(w-w_{old}\\right)^{T}\\left(w-w_{old}\\right) \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "We can develop it:\n",
        "$$\\begin{array}{c}\n",
        "w^{\\star}=\\arg \\min \\frac{1}{2} w^{T} \\Sigma w-\\gamma w^{T} \\mu+\\rho w^{T}w - 2\\rho w^{T}w_{old} + \\rho w_{old}^{T}w_{old}\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Since $\\rho w_{old}^{T}w_{old}$ is a constant term, we can neglect it.\n",
        "\n",
        "Finally, the quadratic programming version of the initial problem is:\n",
        "$$ \\begin{array}{c}\n",
        "w^{\\star}=\\arg \\min \\frac{1}{2} w^{T}(\\Sigma + 2\\rho I_n) w- w^{T}( \\gamma \\mu + 2\\rho w_{old})\\\\\n",
        "\\text { s.c. } \\quad w^{T} \\mathbf{1}=1 \\\\\n",
        "\\quad  \\quad  \\quad  \\quad w_{i} \\geq 0, \\forall i\n",
        "\\end{array}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f0d831-fc66-47d0-bdff-7682305c7a3e",
      "metadata": {
        "id": "e9f0d831-fc66-47d0-bdff-7682305c7a3e"
      },
      "source": [
        "**Q6: We can take the codes from Q5 and update the values of P, q to add the L2 regularization to the optimization. We can test different values of $\\rho$ to see the impact of regularization**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0513041-188e-45f6-98b6-5bee3221f6f8",
      "metadata": {
        "id": "b0513041-188e-45f6-98b6-5bee3221f6f8"
      },
      "outputs": [],
      "source": [
        "num_observation = stock_return.shape[0]\n",
        "index_rebalancement = stock_return['2010':].resample('M').last().index\n",
        "\n",
        "rhos = [0.0, 0.05, 0.5, 100]\n",
        "for ind_rho in rhos:\n",
        "    weights_backtest_2 = pd.DataFrame(index = index_rebalancement, columns = stock_return.columns)\n",
        "    weights_old = np.array([0.25, 0.25, 0.25, 0.25])\n",
        "\n",
        "    for ind in index_rebalancement:\n",
        "        price_tmp = stock_price[:ind].tail(252)\n",
        "        return_tmp = price_tmp.pct_change().dropna()\n",
        "\n",
        "        mus_tmp = #...#\n",
        "        mus_tmp = mus_tmp.values\n",
        "\n",
        "        Sigma_tmp = #...#\n",
        "        Sigma_tmp = Sigma_tmp.values\n",
        "\n",
        "        P = #...#\n",
        "        q = #...#\n",
        "\n",
        "        A = #...#\n",
        "        b = #...#\n",
        "\n",
        "        G = #...#\n",
        "        h = #...#\n",
        "\n",
        "        weights_ridge_tmp = solve_qp(P, q, G, h, A, b, solver = \"ecos\")\n",
        "        weights_backtest_2.loc[ind] = weights_ridge_tmp\n",
        "        weights_old = weights_ridge_tmp\n",
        "\n",
        "    plt.figure()\n",
        "    #### Plot portfolio allocation over time ####\n",
        "    weights_backtest_2.abs().plot(kind='area', stacked=True, cmap='tab20', figsize=(15, 6))\n",
        "    plt.title(\"Backtest + Ridge (rho = \" + str(ind_rho) + \")\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Allocation\")\n",
        "    plt.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.1), fancybox = True, shadow = True, ncol = 4)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}