{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHn5lYJiFx6hvDJb/TzgiE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaetanAm/Master-1-Machine-Learning/blob/main/notebooks/Tutorial1_ML_Asset_Mgt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "0zT3weNoV4Ur",
        "outputId": "f8a45f1b-c934-400f-d31b-6255155a8ffa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unmatched ')' (<ipython-input-1-4a828fccb86a>, line 232)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4a828fccb86a>\"\u001b[0;36m, line \u001b[0;32m232\u001b[0m\n\u001b[0;31m    Ms = (??? - ???)) / ???  # Centered and scaled data\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "# ############################################################\n",
        "# 1 - Data                                                  #\n",
        "# ############################################################\n",
        "\n",
        "# Define the main path\n",
        "mainpath = r\"your_path\"\n",
        "# Load the data\n",
        "all_assets_prices = pd.read_csv(f\"{mainpath}DataForStatsTutorial1.csv\", index_col=???, sep=???, parse_dates=???, dayfirst=True)\n",
        "\n",
        "\n",
        "# ############################################################\n",
        "# 2 - Data Exploration                                       #\n",
        "# ############################################################\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.???(all_assets_prices[[???, ???]])\n",
        "plt.title(\"ES50 and SP500\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend(['DMEquitiesEUR', 'DMEquitiesUSD'])\n",
        "plt.show()\n",
        "\n",
        "# Plot a subset of the data\n",
        "subset = all_assets_prices.???[???:???, [???, ???]]\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(subset)\n",
        "plt.title(\"ES50 and SP500 - From 2019 to 2022\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend(['DMEquitiesEUR', 'DMEquitiesUSD'])\n",
        "plt.show()\n",
        "\n",
        "# Change frequency\n",
        "all_assets_prices_daily = all_assets_prices\n",
        "all_assets_prices_weekly = all_assets_prices.???(???).last()\n",
        "all_assets_prices_monthly = all_assets_prices.???(???).last()\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "print(\"Daily Prices Head:\")\n",
        "print(all_assets_prices_daily.head())\n",
        "print(\"\\nWeekly Prices Head:\")\n",
        "print(all_assets_prices_weekly.head())\n",
        "print(\"\\nMonthly Prices Head:\")\n",
        "print(all_assets_prices_monthly.head())\n",
        "\n",
        "# Function to compute returns from prices\n",
        "def compute_return(price):\n",
        "    ret = price / ??? - 1\n",
        "    return ret\n",
        "\n",
        "# Example: Calculate returns for SP500\n",
        "prices_sp = all_assets_prices_daily['DMEquitiesUSD']\n",
        "returns_sp = compute_return(prices_sp)\n",
        "\n",
        "# Compare with the pct_change function\n",
        "returns_sp_check = prices_sp.pct_change()\n",
        "\n",
        "# Display the first few returns\n",
        "print(\"\\nReturns SP Head:\")\n",
        "print(returns_sp.head())\n",
        "\n",
        "#######################################\n",
        "# 3 - Usual stats                     #\n",
        "#######################################\n",
        "\n",
        "# Function to compute Compound Annual Growth Rate (CAGR)\n",
        "def compute_cagr(price, ann_multiple=252):\n",
        "    n = len(price)\n",
        "    cagr = (price.??? / price.???) ** (???) - 1\n",
        "    return cagr\n",
        "\n",
        "# Example: Calculate CAGR for SP500\n",
        "cagr_sp = compute_cagr(all_assets_prices['DMEquitiesUSD'])\n",
        "print(f'CAGR of SP 500 is: {round(cagr_sp * 100, 2)}%')\n",
        "\n",
        "# Function to compute Volatility\n",
        "def compute_vol(price, ann_multiple=252):\n",
        "    ret = price / price.??? - 1  # Calculate returns\n",
        "    n = len(price)  # Get the length of the time series\n",
        "    mu =???  # Calculate the mean\n",
        "    sigma_daily = np.sqrt(??? / (n - 1))  # Calculate daily volatility\n",
        "    sigma = np.sqrt(???) * sigma_daily  # Annualize the volatility\n",
        "    return sigma\n",
        "\n",
        "# Example: Calculate Volatility for SP500\n",
        "vol_sp = compute_vol(all_assets_prices['DMEquitiesUSD'])\n",
        "print(f'Volatility of SP 500 is: {round(vol_sp * 100, 2)}%')\n",
        "\n",
        "# Comparing with the std function\n",
        "sp_returns = all_assets_prices['DMEquitiesUSD'].pct_change()\n",
        "vol_sp_check = np.sqrt(252)*all_assets_prices['DMEquitiesUSD'].pct_change().std()\n",
        "\n",
        "# Function to compute Drawdown\n",
        "def compute_dd_np(price):\n",
        "    price = price.values  # Convert to numpy array\n",
        "    drawdown = price / np.??? - 1  # Calculate drawdown\n",
        "    return drawdown\n",
        "\n",
        "def compute_dd_pd(df,series):\n",
        "    # Cumulative returns\n",
        "    series_to_retain = df[series]\n",
        "    out_df = pd.DataFrame()\n",
        "    out_df[series] = series_to_retain\n",
        "    out_df['Cumulative'] = out_df / out_df.iloc[0]\n",
        "    # Maximum value up to each point\n",
        "    out_df['Max'] = out_df['Cumulative'].cummax()\n",
        "    # DD\n",
        "    out_df['Drawdown'] = (out_df['Cumulative'] - out_df['Max']) / out_df['Max']\n",
        "    return out_df\n",
        "\n",
        "# Example: Calculate Drawdown for SP500\n",
        "dd_np = compute_dd_np(all_assets_prices['DMEquitiesUSD'])  # Calculate drawdowns with numpy\n",
        "dd_df = compute_dd_pd(all_assets_prices,'DMEquitiesUSD')  # Calculate drawdowns wih pandas\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(dd_df.Drawdown, linewidth=2)\n",
        "plt.title(\"SP500 Drawdown\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Drawdown\")\n",
        "plt.show()\n",
        "\n",
        "mdd = np.min(dd_np)  # Max drawdown\n",
        "print(f\"Max Drawdown of SP 500 = {round(mdd * 100, 2)}%\")\n",
        "print(f\"Max Drawdown of SP 500 = {round(dd_df.Drawdown.min() * 100, 2)}%\")\n",
        "\n",
        "# Function to compute Sharpe Ratio\n",
        "def compute_sr(price, ret_without_risk=0.00, ann_multiple=252):\n",
        "    cagr = compute_cagr(price, ann_multiple)  # CAGR\n",
        "    vol = compute_vol(price, ann_multiple)  # Volatility\n",
        "    sr = (??? - ???) / ???\n",
        "    return sr\n",
        "\n",
        "# Example: Calculate Sharpe Ratio for SP500\n",
        "rf = 0.02  # Risk-free rate\n",
        "sr = compute_sr(all_assets_prices['DMEquitiesUSD'], rf, 252)  # Sharpe Ratio\n",
        "print(f\"Sharpe Ratio of SP 500 = {round(sr, 2)}\")\n",
        "\n",
        "# Examples to get subsets\n",
        "prix_sp_subset1 = all_assets_prices['DMEquitiesUSD'][???:???]\n",
        "prix_sp_subset2 = all_assets_prices['DMEquitiesUSD'][???:???]\n",
        "prix_sp_subset3 = all_assets_prices['DMEquitiesUSD'][???:???]\n",
        "\n",
        "sr_1 = compute_sr(prix_sp_subset1, rf, 252)  # Sharpe Ratio 2000-2007\n",
        "print(f\"Sharpe Ratio of SP500 Index (2000-2007) = {round(sr_1, 2)}\")\n",
        "\n",
        "sr_2 = compute_sr(prix_sp_subset2, rf, 252)  # Sharpe Ratio 2008-2009\n",
        "print(f\"Sharpe Ratio of SP500 Index (2008-2009) = {round(sr_2, 2)}\")\n",
        "\n",
        "sr_3 = compute_sr(prix_sp_subset3, rf, 252)  # Sharpe Ratio 2010-2022\n",
        "print(f\"Sharpe Ratio of SP500 Index (2010-2022) = {round(sr_3, 2)}\")\n",
        "\n",
        "# Rolling Sharpe Ratio\n",
        "rolling_sr = all_assets_prices['DMEquitiesUSD'].???(window=???).???(compute_sr, raw=False)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(rolling_sr)\n",
        "plt.title(\"Rolling Sharpe Ratio\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Sharpe Ratio\")\n",
        "plt.show()\n",
        "\n",
        "# Expanding Sharpe Ratio\n",
        "expanding_sr = all_assets_prices['DMEquitiesUSD'].???().???(compute_sr, raw=False)\n",
        "expanding_sr[~np.isfinite(expanding_sr)] = 0  # Replace non-finite values with 0\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(expanding_sr)\n",
        "plt.title(\"Expanding Sharpe Ratio\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Sharpe Ratio\")\n",
        "plt.show()\n",
        "\n",
        "# Alternative way to calculate expanding Sharpe Ratio wiht lambda\n",
        "expanding_sr = all_assets_prices['DMEquitiesUSD'].???().???(lambda x: compute_sr(x), raw=False)\n",
        "\n",
        "# Replace non-finite values with 0\n",
        "expanding_sr[~np.isfinite(expanding_sr)] = 0\n",
        "\n",
        "# Plotting the Expanding Sharpe Ratio\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(expanding_sr)\n",
        "plt.title(\"Expanding Sharpe Ratio\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Sharpe Ratio\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# #############################################################\n",
        "# 4 - Calculation of Covariances and Correlations            #\n",
        "# #############################################################\n",
        "\n",
        "# Get data\n",
        "eight_assets_prices_daily = all_assets_prices_daily[['DMEquitiesEUR', 'DMEquitiesUSD',\n",
        "                                                      'BondsDEM', 'BondsGBP',\n",
        "                                                      'BondsUSD', 'DMFXCHF',\n",
        "                                                      'DMFXEUR', 'DMFXGBP']]\n",
        "\n",
        "# Calculate returns\n",
        "returns = eight_assets_prices_daily.apply(???)  # Apply: Loop for columns\n",
        "returns = returns.dropna()  # Remove rows that contain NaN\n",
        "\n",
        "# Covariance calculation\n",
        "n = returns.shape[0]  # Number of rows\n",
        "Mc = ??? - ???  # Center the data: M - mean(M)\n",
        "S = (??? @ ???) / (n - 1)  # Classic formula\n",
        "\n",
        "S_check = eight_assets_prices_daily.pct_change().cov()\n",
        "\n",
        "def cov_mtx(ret, ann_multiple=252):\n",
        "    cmtx = ret.cov() * ann_multiple\n",
        "    return cmtx\n",
        "\n",
        "cov_matrix = cov_mtx(returns)\n",
        "print(\"Covariance Matrix:\")\n",
        "print(cov_matrix)\n",
        "\n",
        "# Verification\n",
        "print(\"Checking Covariance Matrix:\")\n",
        "print(cov_mtx(returns) - S * 252)\n",
        "\n",
        "# Correlation calculation\n",
        "Ms = (??? - ???)) / ???  # Centered and scaled data\n",
        "R = (??? @ ???) / (n - 1)  # Also see Wikipedia\n",
        "\n",
        "def corr_mtx(ret):\n",
        "    cmtx = ret.corr()\n",
        "    return cmtx\n",
        "\n",
        "corr_matrix = corr_mtx(returns)\n",
        "print(\"Correlation Matrix:\")\n",
        "print(corr_matrix)\n",
        "\n",
        "# Verification\n",
        "print(\"Checking Correlation Matrix:\")\n",
        "print(corr_mtx(returns) - R)\n",
        "\n",
        "# Plotting the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Correlations on other historical data\n",
        "# Example for the period 2000-2007\n",
        "returns_subset1 = eight_assets_prices_daily.???[???:???].apply(???)\n",
        "rho1 = corr_mtx(returns_subset1)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(rho1, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title(\"Correlation Matrix (2000-2007)\")\n",
        "plt.show()\n",
        "\n",
        "# Example for the period 2008-2009\n",
        "returns_subset2 = eight_assets_prices_daily.???[???:???].apply(compute_return)\n",
        "rho2 = corr_mtx(returns_subset2)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(rho2, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title(\"Correlation Matrix (2008-2009)\")\n",
        "plt.show()\n",
        "\n",
        "# Example for the period 2010-2022\n",
        "returns_subset3 = eight_assets_prices_daily.???[???:???].apply(compute_return)\n",
        "rho3 = corr_mtx(returns_subset3)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(rho3, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title(\"Correlation Matrix (2010-2022)\")\n",
        "plt.show()\n",
        "\n",
        "# #############################################################\n",
        "# 5 - Building Indices                                     #\n",
        "# #############################################################\n",
        "\n",
        "# 5.1 Indices without volatility constraint\n",
        "# Get data (Multiasset)\n",
        "prices_multi_asset_daily = eight_assets_prices_daily\n",
        "\n",
        "# Get data (Equity)\n",
        "prices_equity_daily = all_assets_prices_daily[['DMEquitiesCAD', 'DMEquitiesCHF',\n",
        "                                               'DMEquitiesDEM', 'DMEquitiesFRF',\n",
        "                                               'DMEquitiesGBP', 'DMEquitiesJPY',\n",
        "                                               'DMEquitiesNDQ', 'DMEquitiesUSD']]\n",
        "\n",
        "# Calculate returns\n",
        "return_multi_asset = prices_multi_asset_daily.apply(compute_return)\n",
        "return_equity = prices_equity_daily.apply(compute_return)\n",
        "\n",
        "# Calculate correlations for equities\n",
        "rho_multi_asset = return_multi_asset.corr()\n",
        "rho_equities = return_equity.corr()\n",
        "\n",
        "# Plot correlation matrix for equities\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.???(rho_equities, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title(\"Correlation Matrix for Equities\")\n",
        "plt.show()\n",
        "\n",
        "# Mean correlations\n",
        "mean_rho_equities = rho_equities.values[np.???(rho_equities, k=1)].mean()\n",
        "mean_rho_multi_asset = rho_multi_asset.values[np.???(rho_multi_asset, k=1)].mean()\n",
        "print(f\"Mean correlation for equities: {mean_rho_equities}\")\n",
        "print(f\"Mean correlation for multi-assets: {mean_rho_multi_asset}\")\n",
        "\n",
        "# Monthly correlations\n",
        "return_equities_monthly = prices_equity_daily.???(???).apply(compute_return)\n",
        "rho_equities_monthly = return_equities_monthly.corr()\n",
        "mean_rho_equities_monthly = rho_equities_monthly.values[np.???(rho_equities_monthly, k=1)].mean()\n",
        "print(f\"Mean correlation for equities (monthly): {mean_rho_equities_monthly}\")\n",
        "\n",
        "# Rebalancing dates (quarterly)\n",
        "rebalancing_dates = prices_multi_asset_daily.???(???).last().index\n",
        "\n",
        "# Initialize strategy returns as DataFrames\n",
        "strategy_ret_ew_ma = pd.DataFrame(index=return_multi_asset.index)\n",
        "strategy_ret_ew_ma['ew_ma'] = None\n",
        "strategy_ret_ew_eq = pd.DataFrame(index=return_equity.index)\n",
        "strategy_ret_ew_eq['ew_eq'] = None\n",
        "strategy_ret_vp_ma = pd.DataFrame(index=return_multi_asset.index)\n",
        "strategy_ret_vp_ma['vp_ma'] = None\n",
        "strategy_ret_vp_eq = pd.DataFrame(index=return_equity.index)\n",
        "strategy_ret_vp_eq['vp_eq'] = None\n",
        "\n",
        "equal_weight_ma = np.repeat(1 / return_multi_asset.shape[1], return_multi_asset.shape[1])\n",
        "equal_weight_eq = np.repeat(1 / return_equity.shape[1], return_equity.shape[1])\n",
        "\n",
        "for index_t in range(len(rebalancing_dates) - 1):\n",
        "    t = ???[???]\n",
        "\n",
        "    # Equal weight portfolios\n",
        "    weight_ew_ma = equal_weight_ma\n",
        "    weight_ew_eq = equal_weight_eq\n",
        "\n",
        "    # Data for the past year\n",
        "    data_one_year_multi_asset = return_multi_asset.loc[???:???]\n",
        "    data_one_year_equity = return_equity.loc[???:???]\n",
        "\n",
        "    # Calculate covariance matrices and retain volatilities\n",
        "    vol_ma = np.sqrt(np.???(???(???, 252)))\n",
        "    vol_eq = np.sqrt(np.???(???(???, 252)))\n",
        "\n",
        "    # Calculate weights for volatility parity\n",
        "    weight_vp_ma = equal_weight_ma / vol_ma\n",
        "    weight_vp_ma /= weight_vp_ma.sum()\n",
        "    weight_vp_eq = equal_weight_eq / vol_eq\n",
        "    weight_vp_eq /= weight_vp_eq.sum()\n",
        "\n",
        "    # Rebalancing\n",
        "    index_return = slice(rebalancing_dates[index_t] + pd.Timedelta(days=1),\n",
        "                         rebalancing_dates[index_t + 1])\n",
        "\n",
        "    strategy_ret_ew_ma.loc[index_return,'ew_ma'] = return_multi_asset.loc[???].dot(???)\n",
        "    strategy_ret_ew_eq.loc[index_return,'ew_eq'] = return_equity.loc[???].dot(???)\n",
        "    strategy_ret_vp_ma.loc[index_return,'vp_ma'] = return_multi_asset.loc[???].dot(???)\n",
        "    strategy_ret_vp_eq.loc[index_return,'vp_eq'] = return_equity.loc[???].dot(???)\n",
        "\n",
        "# Backtest\n",
        "strategy_ret_recap = strategy_ret_ew_ma.join(strategy_ret_ew_eq.join(strategy_ret_vp_ma.join(strategy_ret_vp_eq)))\n",
        "strategy_ret_recap.fillna(0, inplace=True)\n",
        "strategy_cumret_recap = (1+strategy_ret_recap).cumprod()\n",
        "\n",
        "# Plotting the strategies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(strategy_cumret_recap)\n",
        "plt.title(\"Initial Strategies\")\n",
        "plt.legend(strategy_ret_recap.columns)\n",
        "plt.show()\n",
        "\n",
        "# Print Sharpe Ratios\n",
        "print('Sharpe Ratio of 4 portfolios:')\n",
        "print(strategy_cumret_recap.apply(compute_sr))\n",
        "\n",
        "# Print Volatility of 4 portfolios\n",
        "print('Volatility of 4 portfolios:')\n",
        "print(strategy_cumret_recap.apply(compute_vol))\n",
        "\n",
        "# Print Sharpe Ratio of equities\n",
        "print('Sharpe Ratio of equities:')\n",
        "print(prices_equity_daily.apply(compute_sr))\n",
        "\n",
        "# Print Sharpe Ratio of assets in multi-asset portfolios\n",
        "print('Sharpe Ratio of assets in multi-asset portfolios:')\n",
        "print(prices_multi_asset_daily.apply(compute_sr))\n",
        "\n",
        "# 5.2 Indices with target volatility\n",
        "# Target Volatility\n",
        "TARGVOL = 0.1\n",
        "\n",
        "# Initialize strategy returns as DataFrames\n",
        "strategy_ret_ew_ma_tv = pd.DataFrame(index=return_multi_asset.index)\n",
        "strategy_ret_ew_ma_tv['ew_ma'] = None\n",
        "strategy_ret_ew_eq_tv = pd.DataFrame(index=return_equity.index)\n",
        "strategy_ret_ew_eq_tv['ew_eq'] = None\n",
        "strategy_ret_vp_ma_tv = pd.DataFrame(index=return_multi_asset.index)\n",
        "strategy_ret_vp_ma_tv['vp_ma'] = None\n",
        "strategy_ret_vp_eq_tv = pd.DataFrame(index=return_equity.index)\n",
        "strategy_ret_vp_eq_tv['vp_eq'] = None\n",
        "\n",
        "# Equal weights\n",
        "equal_weight_ma = np.repeat(1 / return_multi_asset.shape[1], return_multi_asset.shape[1])\n",
        "equal_weight_eq = np.repeat(1 / return_equity.shape[1], return_equity.shape[1])\n",
        "\n",
        "# Rebalancing dates (assuming you have a function to get these)\n",
        "rebalancing_dates = prices_multi_asset_daily.resample('QE').last().index\n",
        "\n",
        "for index_t in range(len(rebalancing_dates) - 1):\n",
        "    t = rebalancing_dates[index_t]\n",
        "\n",
        "    # Data for the past year\n",
        "    data_one_year_multi_asset = return_multi_asset.loc[???:???]\n",
        "    data_one_year_equity = return_equity.loc[???:???]\n",
        "\n",
        "    # Compute ex ante vol\n",
        "    vcv_ma = ???(data_one_year_multi_asset, 252).values\n",
        "    vcv_eq = ???(data_one_year_equity, 252).values\n",
        "\n",
        "    # Calculate volatilities using numpy\n",
        "    vol_ew_ma = np.sqrt(np.???(equal_weight_ma, np.???(vcv_ma, equal_weight_ma)))\n",
        "    vol_ew_eq = np.sqrt(np.???(equal_weight_eq, np.???(vcv_eq, equal_weight_eq)))\n",
        "\n",
        "    # Compute leverage\n",
        "    lev_ew_ma = TARGVOL / ???\n",
        "    lev_ew_eq = TARGVOL / ???\n",
        "\n",
        "    # Adjust weights for target volatility\n",
        "    weight_ew_ma_tv = equal_weight_ma * lev_ew_ma\n",
        "    weight_ew_eq_tv = equal_weight_eq * lev_ew_eq\n",
        "\n",
        "    # Compute covariance matrix for volatility parity\n",
        "    vol_ma = np.sqrt(np.???(???(???, 252).values))\n",
        "    vol_eq = np.sqrt(np.???(???(???, 252).values))\n",
        "\n",
        "    weight_vp_ma = equal_weight_ma / vol_ma\n",
        "    weight_vp_ma /= weight_vp_ma.sum()\n",
        "    weight_vp_eq = equal_weight_eq / vol_eq\n",
        "    weight_vp_eq /= weight_vp_eq.sum()\n",
        "\n",
        "    vol_vp_ma = np.sqrt(np.???(weight_vp_ma, np.???(vcv_ma, weight_vp_ma)))\n",
        "    vol_vp_eq = np.sqrt(np.???(weight_vp_eq, np.???(vcv_eq, weight_vp_eq)))\n",
        "\n",
        "    # Compute leverage for volatility parity\n",
        "    lev_vp_ma = TARGVOL / vol_vp_ma\n",
        "    lev_vp_eq = TARGVOL / vol_vp_eq\n",
        "\n",
        "    weight_vp_ma_tv = weight_vp_ma * lev_vp_ma\n",
        "    weight_vp_eq_tv = weight_vp_eq * lev_vp_eq\n",
        "\n",
        "    # Assign returns for the index range\n",
        "    # Rebalancing\n",
        "    index_return = slice(rebalancing_dates[index_t] + pd.Timedelta(days=1),\n",
        "                         rebalancing_dates[index_t + 1])\n",
        "\n",
        "    strategy_ret_ew_ma_tv.loc[index_return, 'ew_ma'] = return_multi_asset.loc[???].dot(???)\n",
        "    strategy_ret_ew_eq_tv.loc[index_return, 'ew_eq'] = return_equity.loc[???].dot(???)\n",
        "    strategy_ret_vp_ma_tv.loc[index_return, 'vp_ma'] = return_multi_asset.loc[???].dot(???)\n",
        "    strategy_ret_vp_eq_tv.loc[index_return, 'vp_eq'] = return_equity.loc[???].dot(???)\n",
        "\n",
        "# Backtest\n",
        "strategy_ret_recap_tv = strategy_ret_ew_ma_tv.join(strategy_ret_ew_eq_tv.join(strategy_ret_vp_ma_tv.join(strategy_ret_vp_eq_tv)))\n",
        "strategy_ret_recap_tv.fillna(0, inplace=True)\n",
        "strategy_cumret_recap_tv = (1+strategy_ret_recap_tv).cumprod()\n",
        "\n",
        "# Plotting the strategies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(strategy_cumret_recap_tv)\n",
        "plt.title(\"Initial Strategies\")\n",
        "plt.legend(strategy_ret_recap_tv.columns)\n",
        "plt.show()\n",
        "\n",
        "# Print Sharpe Ratios\n",
        "print('Sharpe Ratio of 4 portfolios:')\n",
        "print(strategy_cumret_recap_tv.apply(compute_sr))\n",
        "\n",
        "# Print Volatility of 4 portfolios\n",
        "print('Volatility of 4 portfolios:')\n",
        "print(strategy_cumret_recap_tv.apply(compute_vol))\n",
        "\n",
        "# Print Sharpe Ratio of equities\n",
        "print('Sharpe Ratio of equities:')\n",
        "print(prices_equity_daily.apply(compute_sr))\n",
        "\n",
        "# Print Sharpe Ratio of assets in multi-asset portfolios\n",
        "print('Sharpe Ratio of assets in multi-asset portfolios:')\n",
        "print(prices_multi_asset_daily.apply(compute_sr))\n",
        "\n",
        "\n",
        "# ############################################################\n",
        "# 6 - A first model                                          #\n",
        "# ############################################################\n",
        "\n",
        "# Read the CSV file\n",
        "model_assets_prices = pd.read_csv(f\"{mainpath}DataForModelTutorial1.csv\", index_col=???, sep=???, parse_dates=[???], dayfirst=True)\n",
        "\n",
        "# Transformations\n",
        "model_assets_prices_for_model = model_assets_prices.copy()\n",
        "model_assets_prices_for_model['CorePCE'] = ???\n",
        "model_assets_prices_for_model['Unemployment'] = ???\n",
        "model_assets_prices_for_model['EDSpread'] =???\n",
        "\n",
        "# Prepare inputs for OLS\n",
        "inputs = pd.DataFrame({\n",
        "    'CorePCE': model_assets_prices_for_model['CorePCE'],\n",
        "    'Unemployment': model_assets_prices_for_model['Unemployment'],\n",
        "    'EDSpread': model_assets_prices_for_model['EDSpread'],\n",
        "    'FedFunds': model_assets_prices_for_model['FedFunds']\n",
        "})\n",
        "\n",
        "# Full history OLS regression\n",
        "data_for_ols = pd.DataFrame({'y': model_assets_prices_for_model['US10Y'], **inputs})\n",
        "X = sm.add_constant(data_for_ols.drop(columns='y'))  # Add constant for intercept\n",
        "lin_model_full = sm.???(data_for_ols['y'], ???).???()\n",
        "\n",
        "# Summary of the full model\n",
        "print(lin_model_full.summary())\n",
        "\n",
        "# Predictions\n",
        "data_for_ols['US10Yhat'] = lin_model_full.???(X)\n",
        "\n",
        "# Quick and dirty chart\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(data_for_ols.index, data_for_ols['y'], label='Actual US10Y', color='blue')\n",
        "plt.plot(data_for_ols.index, data_for_ols['US10Yhat'], label='Predicted US10Y', color='red')\n",
        "plt.title('US10Y Actual vs Predicted')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('US10Y')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Last 10 years OLS regression\n",
        "last_10_years = data_for_ols.tail(???)  # Assuming the DataFrame is sorted by date\n",
        "X_last_10y = sm.add_constant(last_10_years.drop(columns=['y','US10Yhat']))\n",
        "lin_model_last_10y = sm.???(last_10_years['y'], ???).???()\n",
        "\n",
        "# Summary of the last 10 years model\n",
        "print(lin_model_last_10y.summary())\n",
        "\n",
        "# Last 5 years OLS regression\n",
        "last_5_years = data_for_ols.tail(???)\n",
        "X_last_5y = sm.add_constant(last_5_years.drop(columns=['y','US10Yhat']))\n",
        "lin_model_last_5y = sm.???(last_5_years['y'], ???).???()\n",
        "\n",
        "# Summary of the last 5 years model\n",
        "print(lin_model_last_5y.summary())"
      ]
    }
  ]
}